{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ab0b12",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5c2ab",
   "metadata": {},
   "source": [
    "The following sheet is the one used on Goolge Cloud Platform to train the classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f132b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array, array_to_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "#from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1387a",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617899b",
   "metadata": {},
   "source": [
    "The below cell is specific for Google Cloud Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95c2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(\"compiled-dataset\")\n",
    "\n",
    "\n",
    "my_prefix = \"Compiled Dataset/Organic/\"\n",
    "filename = \"dataset/Organic/\"\n",
    "blobs = bucket.list_blobs(prefix = my_prefix, delimiter=\"/\")\n",
    "\n",
    "for blob in blobs:\n",
    "    if(blob.name != my_prefix): # ignoring the subfolder itself \n",
    "        file_name = blob.name.replace(my_prefix, filename)\n",
    "        blob.download_to_filename(file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d9397dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31749"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plastic_box = len(os.listdir(\"dataset/Plastic Box\"))\n",
    "plastic_bottle = len(os.listdir(\"dataset/Plastic Bottle\"))\n",
    "plastic_bag = len(os.listdir(\"dataset/Plastic Bag\"))\n",
    "plastic_round_container = len(os.listdir(\"dataset/Plastic Round Container\"))\n",
    "cardboard = len(os.listdir(\"dataset/Cardboard\"))\n",
    "drinking_carton = len(os.listdir(\"dataset/Drinking Carton\"))\n",
    "glass_bottle = len(os.listdir(\"dataset/Glass Bottle\"))\n",
    "glass_cup = len(os.listdir(\"dataset/Glass Cup\"))\n",
    "metal_can = len(os.listdir(\"dataset/Metal Can\"))\n",
    "paper = len(os.listdir(\"dataset/Paper\"))\n",
    "chips_bag = len(os.listdir(\"dataset/Chips Bag\"))\n",
    "organic = len(os.listdir(\"dataset/Organic\"))\n",
    "total = plastic_box + plastic_bottle + plastic_bag + plastic_round_container + cardboard + drinking_carton + glass_bottle + glass_cup + metal_can + paper + chips_bag + organic\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb00b54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plastic box: 2346\n",
      "plastic bottle: 2479\n",
      "plastic bag: 2751\n",
      "plastic round container: 2705\n",
      "cardboard: 2781\n",
      "drinking carton: 2789\n",
      "glass bottle: 2523\n",
      "glass cup: 2548\n",
      "metal can: 2782\n",
      "paper: 2436\n",
      "organic: 2859\n",
      "chips bag: 2750\n"
     ]
    }
   ],
   "source": [
    "print(\"plastic box:\", plastic_box)\n",
    "print(\"plastic bottle:\", plastic_bottle)\n",
    "print(\"plastic bag:\", plastic_bag)\n",
    "print(\"plastic round container:\", plastic_round_container)\n",
    "print(\"cardboard:\", cardboard)\n",
    "print(\"drinking carton:\", drinking_carton)\n",
    "print(\"glass bottle:\", glass_bottle)\n",
    "print(\"glass cup:\", glass_cup)\n",
    "print(\"metal can:\", metal_can)\n",
    "print(\"paper:\", paper)\n",
    "print(\"organic:\", organic)\n",
    "print(\"chips bag:\", chips_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2986792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572e84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset\"\n",
    "material_labels = {'Cardboard': 0, 'Chips Bag': 1, 'Drinking Carton': 2, 'Glass Bottle': 3,\n",
    "                   'Glass Cup': 4, 'Metal Can': 5, 'Organic': 6, 'Paper': 7, 'Plastic Bag':\n",
    "                   8, 'Plastic Bottle': 9, 'Plastic Box': 10, 'Plastic Round Container': 11}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50413ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28580 images belonging to 12 classes.\n",
      "Found 3169 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "DataGen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.1\n",
    ")\n",
    "train_datagen = DataGen.flow_from_directory(\n",
    "    data_path,\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\")\n",
    "validation_datagen = DataGen.flow_from_directory(\n",
    "    data_path,\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34bfccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cardboard': 0, 'Chips Bag': 1, 'Drinking Carton': 2, 'Glass Bottle': 3, 'Glass Cup': 4, 'Metal Can': 5, 'Organic': 6, 'Paper': 7, 'Plastic Bag': 8, 'Plastic Bottle': 9, 'Plastic Box': 10, 'Plastic Round Container': 11}\n",
      "{'Cardboard': 0, 'Chips Bag': 1, 'Drinking Carton': 2, 'Glass Bottle': 3, 'Glass Cup': 4, 'Metal Can': 5, 'Organic': 6, 'Paper': 7, 'Plastic Bag': 8, 'Plastic Bottle': 9, 'Plastic Box': 10, 'Plastic Round Container': 11}\n"
     ]
    }
   ],
   "source": [
    "print(train_datagen.class_indices)\n",
    "print(validation_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f42080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: 28580\n",
      "Validation Images: 3169\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Images:\",train_datagen.samples)\n",
    "print(\"Validation Images:\",validation_datagen.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16eb043",
   "metadata": {},
   "source": [
    "# DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd563811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet169\n",
    "densenet = DenseNet169(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d3ed81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Softmax:0' shape=(None, 12) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layers in densenet.layers:\n",
    "    layers.trainable = False\n",
    "base_output = GlobalAveragePooling2D()(densenet.output)\n",
    "final_output = Dense(12, activation = \"softmax\")(base_output)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3febeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_densenet_model = Model(inputs = densenet.input, outputs = final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10a92ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1e5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience=10)\n",
    "model_save = ModelCheckpoint(\"densenet169_model.h5\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43bb2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8303\n",
      "Epoch 00001: val_loss improved from inf to 0.31151, saving model to densenet169_model.h5\n",
      "893/893 [==============================] - 643s 720ms/step - loss: 0.5449 - accuracy: 0.8303 - val_loss: 0.3115 - val_accuracy: 0.8930\n",
      "Epoch 2/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.8940\n",
      "Epoch 00002: val_loss improved from 0.31151 to 0.28365, saving model to densenet169_model.h5\n",
      "893/893 [==============================] - 82s 92ms/step - loss: 0.3197 - accuracy: 0.8940 - val_loss: 0.2836 - val_accuracy: 0.9006\n",
      "Epoch 3/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9099\n",
      "Epoch 00003: val_loss did not improve from 0.28365\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.2751 - accuracy: 0.9099 - val_loss: 0.2862 - val_accuracy: 0.9003\n",
      "Epoch 4/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9182\n",
      "Epoch 00004: val_loss did not improve from 0.28365\n",
      "893/893 [==============================] - 81s 91ms/step - loss: 0.2486 - accuracy: 0.9182 - val_loss: 0.2877 - val_accuracy: 0.8974\n",
      "Epoch 5/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9247\n",
      "Epoch 00005: val_loss improved from 0.28365 to 0.28247, saving model to densenet169_model.h5\n",
      "893/893 [==============================] - 82s 92ms/step - loss: 0.2307 - accuracy: 0.9247 - val_loss: 0.2825 - val_accuracy: 0.9050\n",
      "Epoch 6/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.9268\n",
      "Epoch 00006: val_loss improved from 0.28247 to 0.28008, saving model to densenet169_model.h5\n",
      "893/893 [==============================] - 82s 92ms/step - loss: 0.2204 - accuracy: 0.9268 - val_loss: 0.2801 - val_accuracy: 0.9047\n",
      "Epoch 7/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9313\n",
      "Epoch 00007: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.2057 - accuracy: 0.9313 - val_loss: 0.2935 - val_accuracy: 0.8990\n",
      "Epoch 8/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9353\n",
      "Epoch 00008: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1988 - accuracy: 0.9353 - val_loss: 0.2852 - val_accuracy: 0.9041\n",
      "Epoch 9/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.9371\n",
      "Epoch 00009: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1894 - accuracy: 0.9371 - val_loss: 0.2907 - val_accuracy: 0.8984\n",
      "Epoch 10/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9383\n",
      "Epoch 00010: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1842 - accuracy: 0.9383 - val_loss: 0.2957 - val_accuracy: 0.9009\n",
      "Epoch 11/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9403\n",
      "Epoch 00011: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1778 - accuracy: 0.9403 - val_loss: 0.2940 - val_accuracy: 0.9006\n",
      "Epoch 12/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9423\n",
      "Epoch 00012: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1724 - accuracy: 0.9423 - val_loss: 0.3087 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9431\n",
      "Epoch 00013: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1699 - accuracy: 0.9431 - val_loss: 0.3117 - val_accuracy: 0.9025\n",
      "Epoch 14/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9444\n",
      "Epoch 00014: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1630 - accuracy: 0.9444 - val_loss: 0.3249 - val_accuracy: 0.8946\n",
      "Epoch 15/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9457\n",
      "Epoch 00015: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1600 - accuracy: 0.9457 - val_loss: 0.3156 - val_accuracy: 0.8981\n",
      "Epoch 16/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9489\n",
      "Epoch 00016: val_loss did not improve from 0.28008\n",
      "893/893 [==============================] - 81s 90ms/step - loss: 0.1555 - accuracy: 0.9489 - val_loss: 0.3280 - val_accuracy: 0.8943\n"
     ]
    }
   ],
   "source": [
    "my_densenet_model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_densenet169 = my_densenet_model.fit(train_datagen, validation_data=validation_datagen, epochs=100, \n",
    "             steps_per_epoch = train_datagen.samples//32,\n",
    "             callbacks=[early_stopping, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5966caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trainHistoryDensenet169', 'wb') as file_pi:\n",
    "    pickle.dump(history_densenet169.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b4eb0",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a766703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "vgg19 = VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3),\n",
    "    pooling = \"avg\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "845afde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in vgg19.layers:\n",
    "    layers.trainable = False\n",
    "fc1 = Dense(4096, activation = \"relu\", name = \"fc1\")(vgg19.output)\n",
    "fc2 = Dense(4096, activation = \"relu\", name = \"fc2\")(fc1)\n",
    "predictions = Dense(12, activation = \"softmax\", name = \"predictions\")(fc2) \n",
    "my_vgg19_model = Model(inputs = vgg19.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5683effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 12)                49164     \n",
      "=================================================================\n",
      "Total params: 38,956,108\n",
      "Trainable params: 18,931,724\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdc0c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.6584\n",
      "Epoch 00001: val_loss improved from inf to 0.79075, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 92s 103ms/step - loss: 1.0047 - accuracy: 0.6584 - val_loss: 0.7907 - val_accuracy: 0.7318\n",
      "Epoch 2/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.7624 - accuracy: 0.7400\n",
      "Epoch 00002: val_loss improved from 0.79075 to 0.64977, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.7624 - accuracy: 0.7400 - val_loss: 0.6498 - val_accuracy: 0.7763\n",
      "Epoch 3/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.6814 - accuracy: 0.7655\n",
      "Epoch 00003: val_loss did not improve from 0.64977\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.6814 - accuracy: 0.7655 - val_loss: 0.6947 - val_accuracy: 0.7665\n",
      "Epoch 4/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.7830\n",
      "Epoch 00004: val_loss improved from 0.64977 to 0.64609, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.6280 - accuracy: 0.7830 - val_loss: 0.6461 - val_accuracy: 0.7873\n",
      "Epoch 5/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.5828 - accuracy: 0.7970\n",
      "Epoch 00005: val_loss improved from 0.64609 to 0.62257, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.5828 - accuracy: 0.7970 - val_loss: 0.6226 - val_accuracy: 0.7999\n",
      "Epoch 6/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.8134\n",
      "Epoch 00006: val_loss improved from 0.62257 to 0.60952, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.5434 - accuracy: 0.8134 - val_loss: 0.6095 - val_accuracy: 0.7902\n",
      "Epoch 7/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8221\n",
      "Epoch 00007: val_loss did not improve from 0.60952\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.5094 - accuracy: 0.8221 - val_loss: 0.6366 - val_accuracy: 0.7936\n",
      "Epoch 8/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.8309\n",
      "Epoch 00008: val_loss improved from 0.60952 to 0.57948, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.4815 - accuracy: 0.8309 - val_loss: 0.5795 - val_accuracy: 0.8151\n",
      "Epoch 9/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.8396\n",
      "Epoch 00009: val_loss improved from 0.57948 to 0.57225, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.4523 - accuracy: 0.8396 - val_loss: 0.5722 - val_accuracy: 0.8182\n",
      "Epoch 10/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8514\n",
      "Epoch 00010: val_loss improved from 0.57225 to 0.54091, saving model to vgg19_model.h5\n",
      "893/893 [==============================] - 93s 104ms/step - loss: 0.4214 - accuracy: 0.8514 - val_loss: 0.5409 - val_accuracy: 0.8249\n",
      "Epoch 11/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8594\n",
      "Epoch 00011: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.3930 - accuracy: 0.8594 - val_loss: 0.5968 - val_accuracy: 0.8116\n",
      "Epoch 12/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8668\n",
      "Epoch 00012: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.3746 - accuracy: 0.8668 - val_loss: 0.5713 - val_accuracy: 0.8189\n",
      "Epoch 13/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8754\n",
      "Epoch 00013: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.3455 - accuracy: 0.8754 - val_loss: 0.5963 - val_accuracy: 0.8261\n",
      "Epoch 14/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8834\n",
      "Epoch 00014: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.3272 - accuracy: 0.8834 - val_loss: 0.5889 - val_accuracy: 0.8170\n",
      "Epoch 15/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8900\n",
      "Epoch 00015: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.3064 - accuracy: 0.8900 - val_loss: 0.5538 - val_accuracy: 0.8318\n",
      "Epoch 16/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.8978\n",
      "Epoch 00016: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.2815 - accuracy: 0.8978 - val_loss: 0.5997 - val_accuracy: 0.8296\n",
      "Epoch 17/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2587 - accuracy: 0.9082\n",
      "Epoch 00017: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.2587 - accuracy: 0.9082 - val_loss: 0.6202 - val_accuracy: 0.8268\n",
      "Epoch 18/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.9127\n",
      "Epoch 00018: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.2415 - accuracy: 0.9127 - val_loss: 0.6915 - val_accuracy: 0.8192\n",
      "Epoch 19/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9183\n",
      "Epoch 00019: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.2278 - accuracy: 0.9183 - val_loss: 0.6446 - val_accuracy: 0.8264\n",
      "Epoch 20/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9258\n",
      "Epoch 00020: val_loss did not improve from 0.54091\n",
      "893/893 [==============================] - 90s 101ms/step - loss: 0.2035 - accuracy: 0.9258 - val_loss: 0.6926 - val_accuracy: 0.8249\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience=10)\n",
    "model_save = ModelCheckpoint(\"vgg19_model.h5\", save_best_only=True, verbose=1)\n",
    "\n",
    "my_vgg19_model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_vgg19 = my_vgg19_model.fit(train_datagen, validation_data=validation_datagen, epochs=100, \n",
    "             steps_per_epoch = train_datagen.samples//32,\n",
    "             callbacks=[early_stopping, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "572a789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trainHistoryVGG19', 'wb') as file_pi:\n",
    "    pickle.dump(history_vgg19.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00851fb",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d6d4ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28580 images belonging to 12 classes.\n",
      "Found 3169 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "DataGen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.1\n",
    ")\n",
    "train_datagen = DataGen.flow_from_directory(\n",
    "    data_path,\n",
    "    batch_size = 32,\n",
    "    target_size = (299,299),\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\")\n",
    "validation_datagen = DataGen.flow_from_directory(\n",
    "    data_path,\n",
    "    batch_size = 32,\n",
    "    target_size = (299,299),\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b4c2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "\n",
    "inceptionresnet = InceptionResNetV2(include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(299,299,3) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc28f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inceptionresnet.layers:\n",
    "    layer.trainable = False\n",
    "base_output = GlobalAveragePooling2D()(inceptionresnet.output)\n",
    "predictions = Dense(12, activation = \"softmax\", name = \"predictions\")(base_output)\n",
    "my_inceptionresnet_model = Model(inputs = inceptionresnet.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "001110db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.8462\n",
      "Epoch 00001: val_loss improved from inf to 0.31439, saving model to inceptionresnet_model.h5\n",
      "893/893 [==============================] - 760s 851ms/step - loss: 0.5028 - accuracy: 0.8462 - val_loss: 0.3144 - val_accuracy: 0.8968\n",
      "Epoch 2/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.8907\n",
      "Epoch 00002: val_loss improved from 0.31439 to 0.27194, saving model to inceptionresnet_model.h5\n",
      "893/893 [==============================] - 173s 194ms/step - loss: 0.3268 - accuracy: 0.8907 - val_loss: 0.2719 - val_accuracy: 0.9091\n",
      "Epoch 3/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9032\n",
      "Epoch 00003: val_loss improved from 0.27194 to 0.26025, saving model to inceptionresnet_model.h5\n",
      "893/893 [==============================] - 173s 193ms/step - loss: 0.2915 - accuracy: 0.9032 - val_loss: 0.2602 - val_accuracy: 0.9135\n",
      "Epoch 4/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.9106\n",
      "Epoch 00004: val_loss did not improve from 0.26025\n",
      "893/893 [==============================] - 170s 191ms/step - loss: 0.2664 - accuracy: 0.9106 - val_loss: 0.2618 - val_accuracy: 0.9148\n",
      "Epoch 5/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.9148\n",
      "Epoch 00005: val_loss improved from 0.26025 to 0.25946, saving model to inceptionresnet_model.h5\n",
      "893/893 [==============================] - 173s 193ms/step - loss: 0.2511 - accuracy: 0.9148 - val_loss: 0.2595 - val_accuracy: 0.9176\n",
      "Epoch 6/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9197\n",
      "Epoch 00006: val_loss improved from 0.25946 to 0.25592, saving model to inceptionresnet_model.h5\n",
      "893/893 [==============================] - 172s 193ms/step - loss: 0.2367 - accuracy: 0.9197 - val_loss: 0.2559 - val_accuracy: 0.9183\n",
      "Epoch 7/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9234\n",
      "Epoch 00007: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.2243 - accuracy: 0.9234 - val_loss: 0.2686 - val_accuracy: 0.9135\n",
      "Epoch 8/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9269\n",
      "Epoch 00008: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.2149 - accuracy: 0.9269 - val_loss: 0.2676 - val_accuracy: 0.9126\n",
      "Epoch 9/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9280\n",
      "Epoch 00009: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.2109 - accuracy: 0.9280 - val_loss: 0.2704 - val_accuracy: 0.9132\n",
      "Epoch 10/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9326\n",
      "Epoch 00010: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.1998 - accuracy: 0.9326 - val_loss: 0.2708 - val_accuracy: 0.9126\n",
      "Epoch 11/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9320\n",
      "Epoch 00011: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.1953 - accuracy: 0.9320 - val_loss: 0.2728 - val_accuracy: 0.9148\n",
      "Epoch 12/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9357\n",
      "Epoch 00012: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.1874 - accuracy: 0.9357 - val_loss: 0.2699 - val_accuracy: 0.9148\n",
      "Epoch 13/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9382\n",
      "Epoch 00013: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 191ms/step - loss: 0.1813 - accuracy: 0.9382 - val_loss: 0.2693 - val_accuracy: 0.9180\n",
      "Epoch 14/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9392\n",
      "Epoch 00014: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 191ms/step - loss: 0.1763 - accuracy: 0.9392 - val_loss: 0.2772 - val_accuracy: 0.9139\n",
      "Epoch 15/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9410\n",
      "Epoch 00015: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 191ms/step - loss: 0.1720 - accuracy: 0.9410 - val_loss: 0.2788 - val_accuracy: 0.9195\n",
      "Epoch 16/100\n",
      "893/893 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9424\n",
      "Epoch 00016: val_loss did not improve from 0.25592\n",
      "893/893 [==============================] - 170s 190ms/step - loss: 0.1676 - accuracy: 0.9424 - val_loss: 0.2676 - val_accuracy: 0.9183\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience=10)\n",
    "model_save = ModelCheckpoint(\"inceptionresnet_model.h5\", save_best_only=True, verbose=1)\n",
    "\n",
    "my_inceptionresnet_model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_inceptionresnet = my_inceptionresnet_model.fit(train_datagen, validation_data=validation_datagen, epochs=100, \n",
    "             steps_per_epoch = train_datagen.samples//32,\n",
    "             callbacks=[early_stopping, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6404a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trainHistoryInceptionResNet', 'wb') as file_pi:\n",
    "    pickle.dump(history_inceptionresnet.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c947742",
   "metadata": {},
   "source": [
    "# NASNetLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9b7487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28580 images belonging to 12 classes.\n",
      "Found 3169 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# preparation for NASNetLarge\n",
    "\n",
    "DataGen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.1\n",
    ")\n",
    "\n",
    "train_datagen_nasnet = DataGen.flow_from_directory(\n",
    "    data_path,\n",
    "    batch_size = 16,\n",
    "    target_size = (331,331),\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\")\n",
    "validation_datagen_nasnet = DataGen.flow_from_directory(\n",
    "    data_path,\n",
    "    batch_size = 16,\n",
    "    target_size = (331,331),\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885b94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import NASNetLarge\n",
    "\n",
    "nasnetlarge = NASNetLarge(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(331,331,3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ecb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in nasnetlarge.layers:\n",
    "    layers.trainable = False\n",
    "    \n",
    "base_output = GlobalAveragePooling2D()(nasnetlarge.output)\n",
    "predictions = Dense(12, activation = \"softmax\")(base_output)\n",
    "my_nasnetlarge_model = Model(inputs = nasnetlarge.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0644e75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8781\n",
      "Epoch 00001: val_loss improved from inf to 0.27129, saving model to nasnetlarge_model.h5\n",
      "1786/1786 [==============================] - 584s 327ms/step - loss: 0.3839 - accuracy: 0.8781 - val_loss: 0.2713 - val_accuracy: 0.9135\n",
      "Epoch 2/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9231\n",
      "Epoch 00002: val_loss improved from 0.27129 to 0.26862, saving model to nasnetlarge_model.h5\n",
      "1786/1786 [==============================] - 579s 324ms/step - loss: 0.2305 - accuracy: 0.9231 - val_loss: 0.2686 - val_accuracy: 0.9154\n",
      "Epoch 3/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.9399\n",
      "Epoch 00003: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.1799 - accuracy: 0.9399 - val_loss: 0.2918 - val_accuracy: 0.9075\n",
      "Epoch 4/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9514\n",
      "Epoch 00004: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.1461 - accuracy: 0.9514 - val_loss: 0.2798 - val_accuracy: 0.9132\n",
      "Epoch 5/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9587\n",
      "Epoch 00005: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.1239 - accuracy: 0.9587 - val_loss: 0.2859 - val_accuracy: 0.9148\n",
      "Epoch 6/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9665\n",
      "Epoch 00006: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.1038 - accuracy: 0.9665 - val_loss: 0.2743 - val_accuracy: 0.9183\n",
      "Epoch 7/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9721\n",
      "Epoch 00007: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.0889 - accuracy: 0.9721 - val_loss: 0.3041 - val_accuracy: 0.9135\n",
      "Epoch 8/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9759\n",
      "Epoch 00008: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.0778 - accuracy: 0.9759 - val_loss: 0.2926 - val_accuracy: 0.9170\n",
      "Epoch 9/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9791\n",
      "Epoch 00009: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.0698 - accuracy: 0.9791 - val_loss: 0.3193 - val_accuracy: 0.9180\n",
      "Epoch 10/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9840\n",
      "Epoch 00010: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.3258 - val_accuracy: 0.9135\n",
      "Epoch 11/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9852\n",
      "Epoch 00011: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.3401 - val_accuracy: 0.9110\n",
      "Epoch 12/100\n",
      "1786/1786 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9869\n",
      "Epoch 00012: val_loss did not improve from 0.26862\n",
      "1786/1786 [==============================] - 575s 322ms/step - loss: 0.0465 - accuracy: 0.9869 - val_loss: 0.3419 - val_accuracy: 0.9139\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience=10)\n",
    "model_save = ModelCheckpoint(\"nasnetlarge_model.h5\", save_best_only=True, verbose=1)\n",
    "my_nasnetlarge_model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_nasnetlarge = my_nasnetlarge_model.fit(train_datagen_nasnet, validation_data=validation_datagen_nasnet, epochs=100, \n",
    "             steps_per_epoch = train_datagen_nasnet.samples//16,\n",
    "             callbacks=[early_stopping, model_save])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e62127",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"trainHistoryNASNetLarge\"\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(history_nasnetlarge.history ,outfile)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
